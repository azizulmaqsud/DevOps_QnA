Real-time Interview Crackers!  Part # 9 (Kubernetes Issues)
Kubernetes Interview QnA 
Deeper Understanding 
the Production 
issues!

Issue List
1. Node Draining Failures
2. Stuck Pods in "Terminating" State
3. Networking Issues between Pods
4. Cluster Autoscaler Failures
5. Persistent Volume Issues with EBS and EFS
6. Resource Exhaustion (CPU/Memory)
7. Misconfigured IAM Roles for Service Accounts
8. Secrets Management Challenges

In Detail
1. Node Draining Failures
•	Issue: Nodes failed to drain during maintenance due to pod disruption constraints or resource allocation issues. This caused workloads to be stuck on the node.
•	Resolution:
o	Used kubectl drain <node> --force --ignore-daemonsets to forcefully evict pods.
o	Adjusted Pod Disruption Budgets to ensure critical workloads had enough replicas during node drain.
2. Stuck Pods in "Terminating" State
•	Issue: Pods failed to terminate cleanly, remaining stuck in the "Terminating" state indefinitely.
•	Resolution:
o	Used kubectl delete pod <pod> --grace-period=0 --force to forcibly delete the pod.
o	Identified underlying issues with resource constraints and resolved with proper configuration.
3. Networking Issues between Pods
•	Issue: Services were not accessible between pods due to misconfigured NetworkPolicies or issues with the CNI (Container Network Interface) plugin.
•	Resolution:
o	Reviewed and updated NetworkPolicies to ensure proper inter-service communication.
o	Reinstalled and reconfigured the CNI plugin (e.g., Calico or Flannel) after identifying issues with its configuration.
4. Cluster Autoscaler Failures
•	Issue: The Kubernetes Cluster Autoscaler failed to scale up nodes in the EKS cluster when resource consumption reached high levels.
•	Resolution:
o	Ensured that the cluster had sufficient IAM permissions to scale nodes.
o	Checked that the auto-scaling group (ASG) had a proper configuration for maximum and minimum node counts.
o	Verified the right resource requests and limits were set for workloads to trigger scaling.
5. Persistent Volume Issues with EBS and EFS
•	Issue: Problems with provisioning persistent volumes (PVs) using EBS and EFS, such as volume attachment failures and incorrect access modes.
•	Resolution:
o	Configured the AWS EBS CSI driver for dynamic provisioning of persistent volumes.
o	Ensured EFS was properly mounted to pods by configuring correct access policies and ensuring NFS client settings were correct.
6. Resource Exhaustion (CPU/Memory)
•	Issue: Nodes were running out of CPU and memory, leading to pod evictions or poor application performance.
•	Resolution:
o	Properly set resource requests and limits for each pod to ensure they were scheduled efficiently.
o	Utilized Horizontal Pod Autoscalers (HPA) to scale applications based on metrics like CPU and memory usage.

7. Misconfigured IAM Roles for Service Accounts
•	Issue: Kubernetes service accounts did not have the required IAM roles for AWS integrations (e.g., for accessing ECR or S3).
•	Resolution:
o	Created IAM roles and linked them to service accounts using eksctl or terraform.
o	Ensured the aws-auth ConfigMap was properly configured to map Kubernetes service accounts to IAM roles.
8. Secrets Management Challenges
•	Issue: Storing and accessing secrets securely in Kubernetes was an ongoing challenge, particularly with sensitive information being stored in plaintext.
•	Resolution:
o	Integrated HashiCorp Vault with Kubernetes for dynamic secrets management and injected secrets into pods using Vault Agent or Kubernetes secrets.
o	Enabled encryption at rest for secrets in Kubernetes using the kube-apiserver configuration.

xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Real-time Interview Crackers!  Part # 10 (Terraform Issues)
Terraform Interview QnA 
Deeper Understanding 
the Prod & Non-Prod
issues!

1. State File Corruption and Drift
•	Issue: State file corruption or drift caused Terraform to act inconsistently, leading to failed plans or untracked infrastructure.
•	Resolution:
o	Moved to remote backends such as AWS S3 with state locking enabled via DynamoDB to prevent state corruption.
o	Used terraform import to bring manually created resources into the Terraform state.
o	Periodically ran terraform refresh and terraform plan to detect and resolve drift between the actual infrastructure and the state file.
2. Dependency Management in Complex Modules
•	Issue: Dependency issues arose in larger Terraform projects, where one module depended on the output of another, leading to failed deployments due to incorrect ordering.
•	Resolution:
o	Utilized depends_on to explicitly define dependencies between resources when necessary.
o	Modularized code into smaller components to reduce interdependencies and make each module more reusable.
3. Provider Version Incompatibility
•	Issue: Compatibility issues between different versions of Terraform providers, especially when using different versions of AWS or Kubernetes providers in the same project.
•	Resolution:
o	Explicitly pinned provider versions using provider "aws" { version = "x.y.z" } to avoid conflicts.
o	Regularly checked provider changelogs to ensure compatibility with the rest of the configuration.
4. Resource Timeout Errors
•	Issue: Long provisioning times for resources like EC2 instances or S3 buckets sometimes caused timeout errors during Terraform apply.
•	Resolution:
o	Increased timeouts in the provider block for certain resources where provisioning was taking longer than usual.
o	Used terraform taint to force a re-creation of a resource if it became stuck during the apply phase.
5. Resource Management Drift (Manual Changes)
•	Issue: Manual changes to infrastructure (outside of Terraform) created discrepancies between Terraform and actual resource configurations.
•	Resolution:
o	Used terraform import to pull manual changes into Terraform's state.
o	Adopted strict version control practices to avoid direct manual changes in favor of Terraform management.
6. IAM Role and Policy Attachments
•	Issue: Attaching IAM roles and policies through Terraform sometimes failed due to missing dependencies or improper syntax.
•	Resolution:
o	Carefully used depends_on to ensure that IAM roles were fully created before attaching policies.
o	Used Terraform data sources to reference existing IAM roles or policies to avoid re-creating resources unnecessarily.
7. Resource Scaling Issues (Auto Scaling Groups)
•	Issue: Auto Scaling Groups (ASGs) didn't scale as expected due to incorrect configurations or issues with instance type provisioning.
•	Resolution:
o	Ensured correct configurations for launch templates and scaling policies in the ASG resource block.
o	Used terraform plan and terraform apply to inspect changes in ASGs and correct any inconsistencies in the desired and minimum capacity settings.
8. Handling Resource Import Errors
•	Issue: Importing existing resources (like RDS instances or EC2 instances) into Terraform sometimes led to errors or required complex manual updates to the state.
•	Resolution:
o	Used terraform import with specific resource identifiers to correctly bring existing resources into the state.
o	Manually edited the state file when necessary, ensuring that the correct attributes were mapped.
9. Provider Authentication Issues
•	Issue: Authentication errors occurred, especially with AWS when configuring Terraform to use specific credentials or access keys.
•	Resolution:
o	Configured the AWS CLI and Terraform to use appropriate AWS credentials files or environment variables.
o	Verified the IAM policies and permissions associated with the credentials to ensure proper access rights.
10. Handling Large Projects with Multiple Workspaces
•	Issue: Managing large-scale Terraform projects with multiple environments (e.g., dev, staging, production) sometimes led to workspace confusion or incorrect resource targeting.
•	Resolution:
o	Used Terraform workspaces to manage different environments and avoid accidentally applying changes to the wrong environment.
o	Implemented proper naming conventions and Terraform modules to keep each environment's configuration clean and isolated.
________________________________________
These issues represent the types of challenges commonly faced with Kubernetes and Terraform, and the resolutions highlight some of the best practices and tools used to mitigate them.

